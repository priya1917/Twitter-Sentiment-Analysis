{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6bPJ2ugaEmux",
        "hBd_XqgtEmu2",
        "k7AOyf6MEmu3",
        "lA6Rn6EFEmu4",
        "fMn4_cTjEmu5",
        "nKnEKLn5Emu7",
        "MNnEjDCXEmu9",
        "wpkAcaTQEmu-",
        "_I55NyuDEmu_",
        "CE5yPu3DEmvA",
        "pR-sAr8HEmvB",
        "0anC8YgKEmvB"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQt31kkBEmuN"
      },
      "source": [
        "# Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIpcXYUEmuX"
      },
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# plotting\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "\n",
        "#tensorflow\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Utility\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "import string\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFErajcJEmuc"
      },
      "source": [
        "data_set = pd.read_csv('Project data.csv',encoding='latin', names = ['polarity','id','date','query','user','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ5dBaqXEmud"
      },
      "source": [
        "# Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ljXg0zPEmue",
        "outputId": "5aff56ae-4e5a-4150-8c46-326b89153045"
      },
      "source": [
        "data_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600000, 6)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfhyoHqhEmug",
        "outputId": "4da9a039-e140-4e11-b966-ce87702ad42a"
      },
      "source": [
        "data_set['polarity'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4], dtype=int64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_phOfhzEmui",
        "outputId": "834438a9-ffe7-4d6c-d2cd-c25ec97bf988"
      },
      "source": [
        "# default polarity for +ve is 4 , change it to 1\n",
        "\n",
        "data_set['polarity'] = data_set['polarity'].replace(4,1)\n",
        "data_set.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811592</td>\n",
              "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mybirch</td>\n",
              "      <td>Need a hug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811594</td>\n",
              "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>coZZ</td>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811795</td>\n",
              "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>2Hood4Hollywood</td>\n",
              "      <td>@Tatiana_K nope they didn't have it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>1467812025</td>\n",
              "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mimismo</td>\n",
              "      <td>@twittera que me muera ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity          id                          date     query  \\\n",
              "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
              "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "5         0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
              "6         0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
              "7         0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
              "8         0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
              "9         0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
              "\n",
              "              user                                               text  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
              "5         joy_wolf                      @Kwesidei not the whole crew   \n",
              "6          mybirch                                        Need a hug   \n",
              "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
              "8  2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
              "9          mimismo                          @twittera que me muera ?   "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OICjH3OiEmul",
        "outputId": "69675d4b-30a0-41d4-bd3f-35ed3c3cc9ef"
      },
      "source": [
        "data_set.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1600000.0</td>\n",
              "      <td>1.600000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.998818e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.5</td>\n",
              "      <td>1.935761e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.467810e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.956916e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.5</td>\n",
              "      <td>2.002102e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.177059e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.329206e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        polarity            id\n",
              "count  1600000.0  1.600000e+06\n",
              "mean         0.5  1.998818e+09\n",
              "std          0.5  1.935761e+08\n",
              "min          0.0  1.467810e+09\n",
              "25%          0.0  1.956916e+09\n",
              "50%          0.5  2.002102e+09\n",
              "75%          1.0  2.177059e+09\n",
              "max          1.0  2.329206e+09"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S7SzlSJEmun",
        "outputId": "b85d60e0-db69-4fd7-9369-f2c72bed6dbb"
      },
      "source": [
        "# check the number of positive vs. negative tagged sentences\n",
        "positives = data_set['polarity'][data_set.polarity == 1 ]\n",
        "negatives = data_set['polarity'][data_set.polarity == 0 ]\n",
        "\n",
        "print('Total length of the data is:         {}'.format(data_set.shape[0]))\n",
        "print('No. of positve tagged sentences is:  {}'.format(len(positives)))\n",
        "print('No. of negative tagged sentences is: {}'.format(len(negatives)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total length of the data is:         1600000\n",
            "No. of positve tagged sentences is:  800000\n",
            "No. of negative tagged sentences is: 800000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZzoy7YEmup"
      },
      "source": [
        "# get a word count of text\n",
        "def word_count(words):\n",
        "    return len(words.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61wV_PCEmuq",
        "outputId": "4a849a66-dbfd-4a0e-f09d-3fda3ac1ee73"
      },
      "source": [
        "# plot word count distribution for both positive and negative\n",
        "'''\n",
        "data_set['word count'] = data_set['text'].apply(word_count)\n",
        "p = data_set['word count'][data_set.polarity == 1]\n",
        "n =data_set['word count'][data_set.polarity == 0]\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.xlim(0,45)\n",
        "plt.xlabel('Word count')\n",
        "plt.ylabel('Frequency')\n",
        "g = plt.hist([p, n], color=['g','r'], alpha=0.5, label=['positive','negative'])\n",
        "plt.legend(loc='upper right')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\ndata_set['word count'] = data_set['text'].apply(word_count)\\np = data_set['word count'][data_set.polarity == 1]\\nn =data_set['word count'][data_set.polarity == 0]\\nplt.figure(figsize=(12,6))\\nplt.xlim(0,45)\\nplt.xlabel('Word count')\\nplt.ylabel('Frequency')\\ng = plt.hist([p, n], color=['g','r'], alpha=0.5, label=['positive','negative'])\\nplt.legend(loc='upper right')\\n\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiWhinN1Emur",
        "outputId": "0884c60a-411b-453c-885d-d643564627a9"
      },
      "source": [
        "# get common words in training dataset\n",
        "from collections import Counter\n",
        "all_words = []\n",
        "for line in list(data_set['text']):\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "      if(len(word)>2):\n",
        "        all_words.append(word.lower())\n",
        "\n",
        "\n",
        "Counter(all_words).most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 518734),\n",
              " ('and', 295675),\n",
              " ('you', 237766),\n",
              " ('for', 214051),\n",
              " ('have', 143295),\n",
              " ('that', 128775),\n",
              " (\"i'm\", 127616),\n",
              " ('but', 124676),\n",
              " ('just', 124454),\n",
              " ('with', 113488),\n",
              " ('was', 102742),\n",
              " ('not', 102160),\n",
              " ('this', 88151),\n",
              " ('get', 80943),\n",
              " ('good', 77367),\n",
              " ('are', 75994),\n",
              " ('like', 75424),\n",
              " ('all', 74076),\n",
              " ('out', 68953),\n",
              " ('your', 64854)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeFGNMhwEmus",
        "outputId": "58da7e1f-3171-4b87-ba49-cb019199887c"
      },
      "source": [
        "''''\n",
        "%matplotlib inline\n",
        "sns.countplot(data_set['polarity'])\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'\\n%matplotlib inline\\nsns.countplot(data_set['polarity'])\\n\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0QktdT6Emut",
        "outputId": "8a12b98f-9277-4cfe-e95c-2d073f32e7fc"
      },
      "source": [
        "# Dropping the columns which are not required\n",
        "data_set.drop(['date','query','user'], axis=1, inplace=True)\n",
        "data_set.drop('id', axis=1, inplace=True)\n",
        "data_set.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>Need a hug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>@Tatiana_K nope they didn't have it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>@twittera que me muera ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity                                               text\n",
              "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1         0  is upset that he can't update his Facebook by ...\n",
              "2         0  @Kenichan I dived many times for the ball. Man...\n",
              "3         0    my whole body feels itchy and like its on fire \n",
              "4         0  @nationwideclass no, it's not behaving at all....\n",
              "5         0                      @Kwesidei not the whole crew \n",
              "6         0                                        Need a hug \n",
              "7         0  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
              "8         0               @Tatiana_K nope they didn't have it \n",
              "9         0                          @twittera que me muera ? "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPSE509-Emuv",
        "outputId": "698f47e6-255d-4c4c-ff70-7a2916dfa9e8"
      },
      "source": [
        "# Checking for null values\n",
        "data_set.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "polarity    0\n",
              "text        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmjeqLg0Emuv"
      },
      "source": [
        "# Typecasting pandas object to a string type\n",
        "data_set['text'] = data_set['text'].astype('str')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb1geJmFEmux",
        "outputId": "6f6d6cc3-812f-4bf4-9abc-be34228707ed"
      },
      "source": [
        "stopword = set(stopwords.words('english'))\n",
        "print(stopword)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'have', \"aren't\", 'after', 'having', 'in', 'when', 'it', 'has', 'had', \"won't\", \"wouldn't\", \"don't\", 'the', 'of', 'between', 'each', \"doesn't\", 'ma', 'down', \"you'll\", 'we', 'yourself', 'further', 'should', 'was', 'own', 'such', 'or', 're', 'needn', \"shan't\", \"hasn't\", 'up', \"wasn't\", \"hadn't\", 'mustn', 'hasn', \"weren't\", 'off', 'won', 'theirs', 'ours', 'both', 'himself', 'haven', 'herself', 'are', 'o', \"haven't\", 'against', 'not', 'this', 'her', 'd', 'why', 'only', 'very', 'did', 've', 'by', \"mustn't\", 'how', 'shouldn', 't', 'our', 'while', \"she's\", 'their', 'm', 'ourselves', 'who', \"that'll\", 'he', 'do', 'ain', \"it's\", \"needn't\", 'shan', \"isn't\", 'out', 'some', 'his', 'will', 'just', 'myself', 'nor', 'hadn', 'my', 'him', 'which', 'there', 'with', 'can', 'itself', 'now', 'you', 'been', 'an', 'these', 'for', 'to', 'during', 'than', 'as', 'i', 'under', 'more', 'weren', 'over', 'few', 'wouldn', 'any', 'again', 'a', 'whom', 'then', 'those', 'yours', 'didn', 'hers', 'all', 'if', 'here', 'and', 'mightn', \"you're\", 'at', 'is', 'most', 'so', 'doesn', 'don', 'above', 'through', \"shouldn't\", 's', \"didn't\", 'about', 'does', \"should've\", 'that', 'wasn', 'isn', 'doing', 'no', 'same', \"you've\", 'other', \"couldn't\", \"mightn't\", 'your', 'themselves', 'before', 'am', 'be', 'until', 'from', 'too', 'me', \"you'd\", 'y', 'couldn', 'she', 'what', 'into', 'where', 'being', 'because', 'aren', 'but', 'on', 'them', 'below', 'they', 'its', 'once', 'll', 'were', 'yourselves'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPJ2ugaEmux"
      },
      "source": [
        "# The Preprocessing steps taken are:\n",
        "\n",
        "Lower Casing: Each text is converted to lowercase.\n",
        "Removing URLs: Links starting with \"http\" or \"https\" or \"www\" are replaced by \"\".\n",
        "\n",
        "Removing Usernames: Replace @Usernames with word \"\". (eg: \"@XYZ\" to \"\")\n",
        "\n",
        "Removing Short Words: Words with length less than 2 are removed.\n",
        "\n",
        "Removing Stopwords: Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. (eg: \"the\", \"he\", \"have\")\n",
        "\n",
        "Lemmatizing: Lemmatization is the process of converting a word to its base form. (e.g: “wolves” to “wolf”)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSXKdM-2Emuz"
      },
      "source": [
        "\n",
        "\n",
        "urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "userPattern = '@[^\\s]+'\n",
        "def process_tweets(tweet):\n",
        "  # Lower Casing\n",
        "    tweet = tweet.lower()\n",
        "    tweet=tweet[1:]\n",
        "    # Removing all URls\n",
        "    tweet = re.sub(urlPattern,'',tweet)\n",
        "    # Removing all @username.\n",
        "    tweet = re.sub(userPattern,'', tweet)\n",
        "    #Remove punctuations\n",
        "    tweet = tweet.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "    #tokenizing words\n",
        "    tokens = word_tokenize(tweet)\n",
        "    #Removing Stop Words\n",
        "    final_tokens = [w for w in tokens if w not in stopword]\n",
        "    #reducing a word to its word stem\n",
        "    wordLemm = WordNetLemmatizer()\n",
        "    finalwords=[]\n",
        "    for w in final_tokens:\n",
        "        if len(w)>1:\n",
        "            word = wordLemm.lemmatize(w)\n",
        "            finalwords.append(word)\n",
        "    return ' '.join(finalwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ch9oyu7LEmu0",
        "outputId": "3c4a2745-067e-4fc0-e949-727e0baaa266"
      },
      "source": [
        "data_set['processed_tweets'] = data_set['text'].apply(lambda x: process_tweets(x))\n",
        "print('Text Preprocessing complete.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCCqXb-mEmu1",
        "outputId": "4b597ff8-ab8c-4d2f-fdfd-53fe06fca718"
      },
      "source": [
        "data_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>text</th>\n",
              "      <th>processed_tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>switchfoot awww thats bummer shoulda got david...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>upset cant update facebook texting might cry r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>kenichan dived many time ball managed save 50 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>nationwideclass behaving im mad cant see</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity                                               text  \\\n",
              "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
              "1         0  is upset that he can't update his Facebook by ...   \n",
              "2         0  @Kenichan I dived many times for the ball. Man...   \n",
              "3         0    my whole body feels itchy and like its on fire    \n",
              "4         0  @nationwideclass no, it's not behaving at all....   \n",
              "\n",
              "                                    processed_tweets  \n",
              "0  switchfoot awww thats bummer shoulda got david...  \n",
              "1  upset cant update facebook texting might cry r...  \n",
              "2  kenichan dived many time ball managed save 50 ...  \n",
              "3                    whole body feel itchy like fire  \n",
              "4           nationwideclass behaving im mad cant see  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBd_XqgtEmu2"
      },
      "source": [
        "# Analizing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7AOyf6MEmu3"
      },
      "source": [
        "# # Positive word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh2hfnJtEmu3",
        "outputId": "ce74773b-af83-457b-d4df-c9159f39389c"
      },
      "source": [
        "'''\n",
        "plt.figure(figsize = (15,15))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(data_set[data_set.polarity == 1].processed_tweets))\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nplt.figure(figsize = (15,15)) \\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(data_set[data_set.polarity == 1].processed_tweets))\\nplt.imshow(wc , interpolation = \\'bilinear\\')\\n\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA6Rn6EFEmu4"
      },
      "source": [
        "# #Negetive word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9OavPb9Emu5",
        "outputId": "d9c68c93-59f7-4730-f1fc-ff02b08e040e"
      },
      "source": [
        "'''\n",
        "plt.figure(figsize = (15,15))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(data_set[data_set.polarity == 0].processed_tweets))\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nplt.figure(figsize = (15,15)) \\nwc = WordCloud(max_words = 2000 , width = 1600 , height = 800).generate(\" \".join(data_set[data_set.polarity == 0].processed_tweets))\\nplt.imshow(wc , interpolation = \\'bilinear\\')\\n'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMn4_cTjEmu5"
      },
      "source": [
        "# Vectorization and Splitting the data\n",
        "Storing input variable-processes_tweets to X and output variable-polarity to y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfjZW18IEmu6"
      },
      "source": [
        "X = data_set['processed_tweets'].values\n",
        "y = data_set['polarity'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XU7AEmBEmu6",
        "outputId": "6122c58d-8aa5-4d13-8630-19f9158fab4e"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1600000,)\n",
            "(1600000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKnEKLn5Emu7"
      },
      "source": [
        "# Convert text to word frequency vectors\n",
        "TF-IDF\n",
        "This is an acronym than stands for Term Frequency – Inverse Document Frequency which are the components of the resulting scores assigned to each word.\n",
        "\n",
        "Term Frequency: This summarizes how often a given word appears within a document.\n",
        "Inverse Document Frequency: This downscales words that appear a lot across documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr7lYbz9Emu7",
        "outputId": "7487ff94-0551-4c7c-e127-b6ff299b500a"
      },
      "source": [
        "#Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "vector = TfidfVectorizer(sublinear_tf=True)\n",
        "X = vector.fit_transform(X)\n",
        "print(f'Vector fitted.')\n",
        "print('No. of feature_words: ', len(vector.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector fitted.\n",
            "No. of feature_words:  762358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMcZSezgEmu8",
        "outputId": "09f3a5d3-e178-4b9c-8cf3-6fc26b8f1541"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1600000, 762358)\n",
            "(1600000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74Tt7CdpEmu8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayeeDnZPEmu9",
        "outputId": "5c6bd8c1-0f37-4fbe-fbc5-ee9704b6e153"
      },
      "source": [
        "print(\"X_train\", X_train.shape)\n",
        "print(\"y_train\", y_train.shape)\n",
        "print()\n",
        "print(\"X_test\", X_test.shape)\n",
        "print(\"y_test\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train (1280000, 762358)\n",
            "y_train (1280000,)\n",
            "\n",
            "X_test (320000, 762358)\n",
            "y_test (320000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNnEjDCXEmu9"
      },
      "source": [
        "# Model Building\n",
        "\n",
        "Model evaluating function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpU9vPlTEmu-"
      },
      "source": [
        "def model_Evaluate(model):\n",
        "    #accuracy of model on training data\n",
        "    acc_train=model.score(X_train, y_train)\n",
        "    #accuracy of model on test data\n",
        "    acc_test=model.score(X_test, y_test)\n",
        "\n",
        "    print('Accuracy of model on training set : {}'.format(acc_train*100))\n",
        "    print('Accuracy of model on test set : {} \\n'.format(acc_test*100))\n",
        "\n",
        "    # Predict values for Test dataset\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print the evaluation metrics for the dataset.\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpkAcaTQEmu-"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTHpN76Emu_",
        "outputId": "2d4b5f30-8a3a-428a-b6bb-4aeb64204d61"
      },
      "source": [
        "lg = LogisticRegression()\n",
        "history=lg.fit(X_train, y_train)\n",
        "model_Evaluate(lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model on training set : 82.29023437500001\n",
            "Accuracy of model on test set : 78.50281249999999 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.76      0.78    159763\n",
            "           1       0.77      0.81      0.79    160237\n",
            "\n",
            "    accuracy                           0.79    320000\n",
            "   macro avg       0.79      0.78      0.78    320000\n",
            "weighted avg       0.79      0.79      0.78    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I55NyuDEmu_"
      },
      "source": [
        "# Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UBwwPmHNEmu_",
        "outputId": "1eded3ef-a2a8-48a6-9e09-317f243e81c4"
      },
      "source": [
        "svm = LinearSVC()\n",
        "svm.fit(X_train, y_train)\n",
        "model_Evaluate(svm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model on training set : 89.192578125\n",
            "Accuracy of model on test set : 77.84687500000001 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77    159763\n",
            "           1       0.77      0.79      0.78    160237\n",
            "\n",
            "    accuracy                           0.78    320000\n",
            "   macro avg       0.78      0.78      0.78    320000\n",
            "weighted avg       0.78      0.78      0.78    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE5yPu3DEmvA"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x04BDRqhEmvA",
        "outputId": "ef4bea9d-58ac-4d14-8308-e8b23fcb5b85"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', max_depth=50)\n",
        "rf.fit(X_train, y_train)\n",
        "model_Evaluate(rf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model on training set : 70.826953125\n",
            "Accuracy of model on test set : 69.3453125 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.61      0.67    159763\n",
            "           1       0.67      0.78      0.72    160237\n",
            "\n",
            "    accuracy                           0.69    320000\n",
            "   macro avg       0.70      0.69      0.69    320000\n",
            "weighted avg       0.70      0.69      0.69    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-sAr8HEmvB"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0FrUlXpEmvB",
        "outputId": "8368e133-bcdd-44f7-8686-ef6a1594cb6a"
      },
      "source": [
        "nb = BernoulliNB()\n",
        "nb.fit(X_train, y_train)\n",
        "model_Evaluate(nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of model on training set : 83.894296875\n",
            "Accuracy of model on test set : 77.2934375 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78    159763\n",
            "           1       0.78      0.76      0.77    160237\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0anC8YgKEmvB"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBJKwkKjEmvC"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROA51hiPEmvC",
        "outputId": "06da4057-9d60-480f-a6c2-c998125a6531"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.4.3'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjwqLxSxEmvC",
        "outputId": "4b62ef1f-eb80-4a79-d126-76235af46b3c"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(data_set.processed_tweets)\n",
        "sequences = tokenizer.texts_to_sequences(data_set.processed_tweets)\n",
        "tweets = pad_sequences(sequences, maxlen=max_len)\n",
        "print(tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...  759 1865    2]\n",
            " [   0    0    0 ...   11  187 1283]\n",
            " [   0    0    0 ...  368    6 3132]\n",
            " ...\n",
            " [   0    0    0 ...  123  504 1746]\n",
            " [   0    0    0 ...  415 4997   12]\n",
            " [   0    0    0 ...    0    0  458]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYNB_tU0EmvD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tweets, data_set.polarity.values, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4JJsA3XEmvD",
        "outputId": "174b0620-fc21-4abc-d1c1-9c6e5ab816fe"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_words, 128))\n",
        "model2.add(layers.LSTM(64,dropout=0.5))\n",
        "model2.add(layers.Dense(16, activation='relu'))\n",
        "model2.add(layers.Dense(8, activation='relu'))\n",
        "model2.add(layers.Dense(1,activation='sigmoid'))\n",
        "model2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint2 = ModelCheckpoint(\"rnn_model.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model2.fit(X_train, y_train, epochs=10,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 4535s 113ms/step - loss: 0.4900 - accuracy: 0.7606 - val_loss: 0.4560 - val_accuracy: 0.7826\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.78262, saving model to rnn_model.hdf5\n",
            "Epoch 2/10\n",
            " 6874/40000 [====>.........................] - ETA: 58:12 - loss: 0.4516 - accuracy: 0.7871"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tShJhvDZEmvE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}